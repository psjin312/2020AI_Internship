# 실습 예제
> 3주차에 학습한 세 가지 classifier들이 각각 어떤 식으로 전이학습에 적용될 수 있는지 알아보기   
> 각각의 classifieer를 기본적인 이미지 데이터셋으로 학습시켜보기

* 작은 데이터셋 준비
> 제한된 컴퓨팅 연산 능력을 가진 환경에서 모델학습이 더 빠르게 이루어질 수 있도록 작은 버전의 데이터셋을 활용한다.
> 4주차/CatDogDataSet.py 파일   

* convolutional base에서 특징 추출하기
> convolutional base는 특징을 추출하는 용도로 사용한다.      
> 우리가 원하는 classifier에 입력값으로 들어가서 고양이인지 개인지 분류하게 된다.
> 4주차/Extract features.py 파일

# 세 가지 Classifiers
* Fully-connected layers, 완전 연결 계층
> 첫 번째 방법으로 사용할 분류기는 완전 연결 계층   
> 이 분류기는 완전 연결 계층들을 쌓아서 만든 형태로, convolutional base에서 추출된 특징 벡터를 입력받는다.   
> FullyConnectedLayers.py   
> ![image](https://user-images.githubusercontent.com/34376342/97689797-74878600-1adf-11eb-9843-64415753133c.png)   
> 완전 연결 계층의 정확도   

> ![image](https://user-images.githubusercontent.com/34376342/97689903-97199f00-1adf-11eb-9078-c501ce8900dc.png)   
> 완전 연결 계층 모델의 손실함수값   
* 결과에 대한 고찰   
> 검증 데이터셋에 대한 정확도는 0.85로, 작은 데이터셋을 생각했을 때 나쁘지 않은 결과라고 생각된다.   
> 모델은 과적합이 되었다. 학습 데이터에 대한 성능과 검증 데이터에 대한 성능에 큰 차이가 있다.

* Global average pooling, 평균 풀링
> ![image](https://user-images.githubusercontent.com/34376342/97690931-0643c300-1ae1-11eb-84d2-9b48667403ec.png)   
> 평균 풀링 모델의 정확도   

> ![image](https://user-images.githubusercontent.com/34376342/97690991-1a87c000-1ae1-11eb-971d-2641ce438b21.png)   
> 평균 풀링 모델의 손실함수값  
* 결과에 대한 고찰
> 검증 데이터에 대한 정확도는 완전 연결 계층 모델과 비슷하다.   
> 이 모델은 완전 연결 계층 모델만큼 과적합되지 않았다.

* Linear support vector machines, 선형 서포트 벡터 머신
> 데이터 합치기
    svm_features = np.concatenate((train_features, validation_features))
    svm_labels = np.concatenate((train_labels, validation_labels))


> ![image](https://user-images.githubusercontent.com/34376342/97691527-d0eba500-1ae1-11eb-976c-69c590f471e2.png)   
> SVM 모델의 정확도   
* 결과에 대한 고찰
> 모델의 정확도는 약 0.86으로, 이전의 모델들과 비슷하다.   
> 모델은 거의 과적합이 되었다.   
> 모델의 정확도는 일반적으로 훈련 데이터 샘플의 수가 늘어남에 따라 커져야한다. 하지만, 그래프에는 이러한 양상이 나타나지 
> 않았다. 이는 아마 과적합이 되었기 때문일 것이다.
    

